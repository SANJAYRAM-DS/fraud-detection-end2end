{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf80188e",
   "metadata": {},
   "source": [
    "## Step 1: Business & Strategy Layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ee9eb7",
   "metadata": {},
   "source": [
    "### Problem Framing\n",
    "\n",
    "> _\"What are we solving? Why does it matter?\"_\n",
    "\n",
    "#### Business Problem\n",
    "Insurance companies suffer major financial losses due to **fraudulent claims**. Manual detection is slow, expensive, and inconsistent. We want to **build an ML system** that can detect suspicious claims **automatically and early**.\n",
    "\n",
    "#### ML Framing\n",
    "\n",
    "| Aspect                 | Description                                                |\n",
    "|------------------------|------------------------------------------------------------|\n",
    "| **Type of ML Problem** | **Classification** (Binary)                                |\n",
    "| **Input**              | Structured tabular data from customer claims               |\n",
    "| **Target**             | `FraudFound_P` → `1` (fraud), `0` (non-fraud)              |\n",
    "| **Supervised?**        | Yes — historical data is labeled                           |\n",
    "| **Real-World Impact**  | Save money, reduce risk, increase trust                    |\n",
    "\n",
    "#### Framing Checklist\n",
    "- [x] Clear business goal\n",
    "- [x] Framed as ML classification problem\n",
    "- [x] Labeled historical data available\n",
    "- [x] Reasonable to automate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29899f56",
   "metadata": {},
   "source": [
    "### Success Metrics Definition\n",
    "\n",
    "> _\"How do we define success?\"_\n",
    "\n",
    "#### Business Metrics\n",
    "- **Amount of money saved** by catching fraud early\n",
    "- **Reduction in investigation time**\n",
    "- **Improved claim processing efficiency**\n",
    "\n",
    "#### ML Metrics\n",
    "\n",
    "| Metric       | Why it matters                                                    |\n",
    "|--------------|-------------------------------------------------------------------|\n",
    "| **Recall**   | Catch as many fraudulent cases as possible (minimize false negs) |\n",
    "| **Precision**| Avoid wrongly flagging legit claims (minimize false positives)   |\n",
    "| **F1 Score** | Balance between precision and recall                              |\n",
    "| **AUC-ROC**  | Overall model discrimination power                                |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bcf6fe",
   "metadata": {},
   "source": [
    "### 1.3 Stakeholder Mapping & Feedback Loops\n",
    "\n",
    "> _\"Who cares about this model? Who uses it? How do we get feedback?\"_\n",
    "\n",
    "#### Stakeholders\n",
    "\n",
    "| Role                | Involvement                                 |\n",
    "|---------------------|---------------------------------------------|\n",
    "| **Data Science Team**   | Model development and evaluation         |\n",
    "| **Fraud Investigators** | Use model predictions to prioritize cases|\n",
    "| **Claims Managers**     | Business decision-makers                 |\n",
    "| **IT/DevOps**           | Deployment and integration support       |\n",
    "\n",
    "#### Feedback Loops\n",
    "\n",
    "| Type               | Example                                                             |\n",
    "|--------------------|---------------------------------------------------------------------|\n",
    "| **Human-in-loop**  | Fraud team flags false positives/negatives, sent back to retrain    |\n",
    "| **Batch retraining**| Model retrained monthly on new verified claims                    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca976ba",
   "metadata": {},
   "source": [
    "###Cost vs Impact Modeling\n",
    "\n",
    "> _\"Is the effort worth it? What are the tradeoffs?\"_\n",
    "\n",
    "#### Financial Impact\n",
    "\n",
    "| Scenario                     | Estimated Cost                         |\n",
    "|-----------------------------|----------------------------------------|\n",
    "| False Negative (miss fraud) | ₹50,000+ per claim lost                |\n",
    "| False Positive (flag legit) | ₹1,000 investigation cost              |\n",
    "| Average fraud rate          | ~10%                                   |\n",
    "| Model catch rate goal       | 80–90% of frauds                       |\n",
    "\n",
    "#### Trade-Offs\n",
    "\n",
    "- **High recall** → more frauds caught, but more false alarms\n",
    "- **High precision** → fewer false alarms, but some frauds may slip\n",
    "\n",
    "> We balance this with **cost-weighted metrics** and stakeholder feedback.\n",
    "\n",
    "#### Tools\n",
    "- ROI simulation with Python (`cost_matrix`, sensitivity analysis)\n",
    "- SHAP for cost-aware interpretability\n",
    "- Business simulation notebooks (optional in later phases)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
